{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46af8af9",
   "metadata": {},
   "source": [
    "<img src=\"./IMTA.png\" alt=\"Logo IMT Atlantique\" width=\"300\"/>\n",
    "\n",
    "##  **Frugal AI : Data Scarcity on Prostate MRI**\n",
    "## TAF Health - UE B - 2025/2026 \n",
    "\n",
    "Pierre-Henri.Conze@imt-atlantique.fr - Vincent.Jaouen@imt-atlantique.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a14243",
   "metadata": {},
   "source": [
    "\n",
    "In this lab, we will work with the **Prostate158** dataset (Mid-Axial slices). \n",
    "We want to understand the impact of **training data size** and **augmentation** on segmentation performance.\n",
    "\n",
    "**Dataset**:\n",
    "*   Images: T2-weighted MRI slices of the prostate-\n",
    "*   Labels: Prostate segmentation masks.\n",
    "\n",
    "**Plan:**\n",
    "1.  **Setup**: Load `prostate158` dataset and define a fixed validation split.\n",
    "2.  **Part I (Scarcity)**: Train specific U-Nets on very small subsets (e.g., 5, 10, 20 images) without augmentation.\n",
    "3.  **Part II (Augmentation)**: Repeat the training on the smallest subsets using extensive Data Augmentation.\n",
    "4.  **Analysis**: Compare learning curves and final Dice scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1566ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "    print(\"Running on Google Colab. Installing dependencies...\")\n",
    "    \n",
    "    # 1. Install necessary libraries\n",
    "    !pip install -q 'monai[nibabel, tqdm]'\n",
    "    !pip install -q matplotlib pyyaml\n",
    "    \n",
    "    # 2. Clone the repository to access data and utilities\n",
    "    repo_name = \"HealthLabs-IMTA\"\n",
    "    repo_url = \"https://github.com/vhxjaouen/HealthLabs-IMTA.git\"\n",
    "\n",
    "    # Check if we are already in the repository (e.g. after a restart)\n",
    "    current_path = os.getcwd()\n",
    "    if os.path.basename(current_path) == \"notebooks\" and os.path.basename(os.path.dirname(current_path)) == repo_name:\n",
    "        print(f\"Already in the repository: {current_path}\")\n",
    "    else:\n",
    "        # Clone if strictly necessary\n",
    "        if not os.path.exists(repo_name):\n",
    "            print(f\"Cloning repository {repo_name}...\")\n",
    "            !git clone {repo_url}\n",
    "        \n",
    "        # Change working directory to the notebooks folder\n",
    "        target_dir = os.path.join(repo_name, \"notebooks\")\n",
    "        if os.path.exists(target_dir):\n",
    "            os.chdir(target_dir)\n",
    "            print(f\"Changed working directory to {os.getcwd()}\")\n",
    "            \n",
    "            # Avoid confusion: remove the duplicate notebook from the cloned repository\n",
    "            colab_notebook_name = \"04_frugalAI_colab.ipynb\"\n",
    "            if os.path.exists(colab_notebook_name):\n",
    "                os.remove(colab_notebook_name)\n",
    "                print(f\"Removed duplicate notebook {colab_notebook_name} from cloned repo to avoid version confusion.\")\n",
    "        else:\n",
    "            print(\"Warning: Could not find notebooks directory. Please check the repository structure.\")\n",
    "            \n",
    "    print(\"Dependencies installed and environment set up.\")\n",
    "else:\n",
    "    print(\"Running locally.\")\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Training will be very slow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# sys.path.append(os.path.abspath(\"..\")) # Removed as we use the installed package now\n",
    "import torch\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityRangePercentilesd,\n",
    "    RandFlipd, RandRotate90d, RandZoomd, RandShiftIntensityd, RandGaussianNoised,\n",
    "    EnsureTyped, SpatialPadd, CenterSpatialCropd, Resized\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "set_determinism(seed=29200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da412e8c",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We will parse the `dataset.json` provided with the dataset to get image/label pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_dir = \"../datasets/prostate158_MidAxial\"\n",
    "json_path = os.path.join(data_dir, \"dataset.json\")\n",
    "\n",
    "# Load dataset.json\n",
    "with open(json_path) as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "# Extract training paths (relative paths in JSON need to be joined with data_dir)\n",
    "data_dicts = []\n",
    "for entry in schema[\"training\"]:\n",
    "    # json entries: \"./imagesTr/xxx.nii.gz\"\n",
    "    img_path = os.path.join(data_dir, entry[\"image\"].replace(\"./\", \"\"))\n",
    "    lbl_path = os.path.join(data_dir, entry[\"label\"].replace(\"./\", \"\"))\n",
    "    data_dicts.append({\"image\": img_path, \"label\": lbl_path})\n",
    "\n",
    "print(f\"Total available images: {len(data_dicts)}\")\n",
    "\n",
    "# Check one pair\n",
    "print(f\"Sample Image: {data_dicts[0]['image']}\")\n",
    "\n",
    "# Define Fixed Split (Last 30 for Validation)\n",
    "val_size = 30\n",
    "val_files = data_dicts[-val_size:]\n",
    "train_pool = data_dicts[:-val_size]\n",
    "\n",
    "print(f\"Validation set size: {len(val_files)}\")\n",
    "print(f\"Training pool size: {len(train_pool)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd038ee",
   "metadata": {},
   "source": [
    "## 2. Transforms Pipeline\n",
    "\n",
    "We setup the MONAI transforms.\n",
    "*   **Preprocessing**: Load, Channel First, Normalize Intensity (1st-99th percentile).\n",
    "*   **Augmentation**: Flips, Rotation, Zoom, Intensity Shift (activated only if `augment=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2241a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(augment=False):\n",
    "    # Base Transforms\n",
    "    transforms_list = [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=-1), \n",
    "        Resized(keys=[\"image\", \"label\"], spatial_size=(256, 256), mode=(\"bilinear\", \"nearest\")),\n",
    "        ScaleIntensityRangePercentilesd(\n",
    "            keys=\"image\", lower=1, upper=99, \n",
    "            b_min=0.0, b_max=1.0, clip=True\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    "    \n",
    "    # Augmentation\n",
    "    if augment:\n",
    "        transforms_list += [\n",
    "            # Geometric\n",
    "            # Vertical Flip (Axis 1) is anatomically more plausible than L/R or random rotation here\n",
    "            RandFlipd(keys=[\"image\", \"label\"], spatial_axis=1, prob=0.5), \n",
    "            RandZoomd(keys=[\"image\", \"label\"], min_zoom=0.9, max_zoom=1.1, mode=[\"area\", \"nearest\"], prob=0.3),\n",
    "            \n",
    "            # Intensity\n",
    "            RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n",
    "            RandGaussianNoised(keys=[\"image\"], prob=0.1, mean=0.0, std=0.05),\n",
    "        ]\n",
    "        \n",
    "    return Compose(transforms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b389a",
   "metadata": {},
   "source": [
    "## 3. Experiment Runner\n",
    "\n",
    "We reuse the configuration from `segmentation.yaml` but override channel settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from healthlabs_imta.utils.training import train_segmentation\n",
    "from healthlabs_imta.utils.model_utils import model_factory\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "# Load Config\n",
    "# import pkg_resources\n",
    "# Try to load from installed package or fallback to relative path?\n",
    "# For simplicity, we can use the package structure if data is included, but config yaml is data.\n",
    "# The user kept data handling as \"Keep datasets at root\" but configs moved to package.\n",
    "# So we should load config from the package path.\n",
    "import os\n",
    "import healthlabs_imta\n",
    "package_dir = os.path.dirname(healthlabs_imta.__file__)\n",
    "config_path = os.path.join(package_dir, \"configs\", \"segmentation.yaml\")\n",
    "\n",
    "with open(config_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Override config for this dataset\n",
    "cfg[\"data\"][\"data_dir\"] = data_dir\n",
    "cfg[\"model\"][\"in_channels\"] = 1   # Single channel MRI\n",
    "cfg[\"model\"][\"out_channels\"] = 1  # Binary segmentation\n",
    "cfg[\"training\"][\"max_epochs\"] = 30  # Set global default duration\n",
    "\n",
    "def run_experiment(n_train_samples, augment, max_epochs=None):\n",
    "    # Use config value if max_epochs not provided\n",
    "    if max_epochs is None:\n",
    "        max_epochs = cfg[\"training\"][\"max_epochs\"]\n",
    "\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Running Experiment: N={n_train_samples}, Augmentation={augment}, Epochs={max_epochs}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # 1. Deterministic Subset\n",
    "    train_subset = train_pool[:n_train_samples]\n",
    "    \n",
    "    # 2. Dataloaders\n",
    "    train_ds = CacheDataset(\n",
    "        data=train_subset, \n",
    "        transform=get_transforms(augment=augment), \n",
    "        cache_rate=1.0, num_workers=2\n",
    "    )\n",
    "    val_ds = CacheDataset(\n",
    "        data=val_files, \n",
    "        transform=get_transforms(augment=False), \n",
    "        cache_rate=1.0, num_workers=2\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # 3. Model Setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model_factory(cfg[\"model\"]).to(device)\n",
    "    loss_fn = DiceCELoss(sigmoid=True, to_onehot_y=False)\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # 4. Training\n",
    "    history = train_segmentation(\n",
    "        model, train_loader, val_loader,\n",
    "        loss_fn, dice_metric, optimizer,\n",
    "        device=device, max_epochs=max_epochs,\n",
    "        overlay_fn=None # Disable plotting during loop\n",
    "    )\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5173bd9",
   "metadata": {},
   "source": [
    "## 4. Part I: Scarcity Impact (No Augmentation)\n",
    "\n",
    "Train with **5, 10, 40** images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45644c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_aug = {}\n",
    "sample_sizes = [100,50,20]\n",
    "\n",
    "for n in sample_sizes:\n",
    "    # We use 50 epochs for a fair comparison with the augmentation part\n",
    "    (train_losses, val_dices, best_dice, weights), _ = run_experiment(n, augment=False, max_epochs=50)\n",
    "    results_no_aug[n] = val_dices\n",
    "    print(f\"-> Final Best Dice (N={n}, No Aug): {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad08b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_aug = {}\n",
    "aug_sample_sizes = [50,20]\n",
    "\n",
    "for n in aug_sample_sizes:\n",
    "    (train_losses, val_dices, best_dice, weights), _ = run_experiment(n, augment=True, max_epochs=50)\n",
    "    results_aug[n] = val_dices\n",
    "    print(f\"-> Final Best Dice (N={n}, Aug): {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f9c48e",
   "metadata": {},
   "source": [
    "## 6. Analysis and Visualization\n",
    "\n",
    "Compare the validation Dice curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ff56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "colors = {5: 'r', 10: 'g', 20: 'orange', 40: 'b', 50: 'm', 100: 'k'} # Adjusted colors\n",
    "\n",
    "# Plot No Aug\n",
    "for n, dices in results_no_aug.items():\n",
    "    c = colors.get(n, 'gray') # Gray fallback if size not in dict\n",
    "    plt.plot(dices, label=f'N={n} (No Aug)', color=c, linestyle='-', linewidth=2)\n",
    "\n",
    "# Plot Aug\n",
    "for n, dices in results_aug.items():\n",
    "    c = colors.get(n, 'gray')\n",
    "    plt.plot(dices, label=f'N={n} (Aug)', color=c, linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title(\"Prostate Segmentation: Impact of Scarcity & Augmentation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Dice\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f87f870",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Part III: Semi-Supervised Learning (Student-Teacher)\n",
    "\n",
    "We simulate a scenario where we have **100 images** available, but only **50 are labeled**.\n",
    "Can we leverage the 50 \"unlabeled\" images to improve the performance of a model trained on only 50 labeled examples?\n",
    "\n",
    "**Strategy (Self-Training / Pseudo-Labeling):**\n",
    "1.  **Train Teacher**: Use the 50 labeled images to train a model (Teacher).\n",
    "2.  **Generate Pseudo-Labels**: Use the Teacher to predict segmentation masks for the 50 unlabeled images.\n",
    "3.  **Train Student**: Train a new model (Student) on the **combined dataset** (50 Labeled + 50 Pseudo-Labeled).\n",
    "4.  **Compare**: Student performance vs. Teacher (N=50) vs. Oracle (N=100 Labeled).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import SaveImaged\n",
    "from monai.inferers import sliding_window_inference\n",
    "import nibabel as nib\n",
    "from monai.transforms import Resize\n",
    "import shutil\n",
    "\n",
    "# --- Experiment Configuration ---\n",
    "n_labeled = 50       # Number of Ground Truth images to use\n",
    "n_unlabeled = 50     # Number of additional images to pseudo-label\n",
    "ssl_epochs = 50      # Training epochs for both Teacher and Student\n",
    "\n",
    "print(f\"Configuration: {n_labeled} Labeled, {n_unlabeled} Unlabeled, {ssl_epochs} Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee7ddc",
   "metadata": {},
   "source": [
    "### 7.1. Train the Teacher\n",
    "We start by training a \"Teacher\" model on the available labeled data (e.g., 50 images). This follows the standard supervised training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Step 1: Training Teacher (N={n_labeled}) ---\")\n",
    "\n",
    "# Train Teacher using the existing experiment runner\n",
    "# We store the results to compare later\n",
    "(teacher_losses, teacher_dices, teacher_best_dice, teacher_weights), teacher_model = run_experiment(n_labeled, augment=True, max_epochs=ssl_epochs)\n",
    "\n",
    "print(f\"Teacher Best Validation Dice: {teacher_best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5187961f",
   "metadata": {},
   "source": [
    "### 7.2. Generate Pseudo-Labels\n",
    "Now that we have a trained Teacher, we use it to predict segmentation masks for the \"unlabeled\" images. These predictions serve as \"Pseudo-Labels\" for the Student.\n",
    "\n",
    "**Crucial Step**: We must ensure the generated pseudo-labels match the exact file structure (dimensions, spacing) of the original data so they can be loaded correctly later. This involves:\n",
    "1. Predicting inference masks (which are usually 256x256 due to our transforms).\n",
    "2. Resizing them *back* to the original image native resolution (e.g., 270x270).\n",
    "3. Ensuring the NIfTI file format (3D vs 2D dimensions) matches the source inputs exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70648ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Step 2: Generating Pseudo-Labels for {n_unlabeled} images ---\")\n",
    "\n",
    "# 1. Prepare Teacher for Inference\n",
    "teacher_model.load_state_dict(teacher_weights)\n",
    "teacher_model.eval()\n",
    "\n",
    "# 2. Select Unlabeled Data\n",
    "# We select the images *immediately following* the labeled set in our training pool to simulate unlabeled data.\n",
    "unlabeled_start = n_labeled\n",
    "unlabeled_end = min(n_labeled + n_unlabeled, len(train_pool))\n",
    "unlabeled_data = train_pool[unlabeled_start:unlabeled_end]\n",
    "\n",
    "print(f\"Generating labels for images {unlabeled_start} to {unlabeled_end}...\")\n",
    "\n",
    "# 3. Setup Output Directory\n",
    "pseudo_label_dir = os.path.join(data_dir, \"pseudo_labels\")\n",
    "if os.path.exists(pseudo_label_dir):\n",
    "    shutil.rmtree(pseudo_label_dir) # Ensure a clean start\n",
    "os.makedirs(pseudo_label_dir, exist_ok=True)\n",
    "\n",
    "pseudo_labeled_data = []\n",
    "infer_transforms = get_transforms(augment=False) # No augmentation for inference\n",
    "\n",
    "# 4. Inference Loop\n",
    "with torch.no_grad():\n",
    "    for i, item in enumerate(unlabeled_data):\n",
    "        # A. Load and Preprocess\n",
    "        # Create a dictionary item to reuse the existing transform pipeline\n",
    "        temp_item = {\"image\": item[\"image\"], \"label\": item[\"image\"]} \n",
    "        input_data = infer_transforms(temp_item)\n",
    "        input_tensor = input_data[\"image\"].unsqueeze(0).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        \n",
    "        # B. Predict (Teacher)\n",
    "        outputs = teacher_model(input_tensor)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        start_mask = (outputs > 0.5).float().cpu().numpy()[0, 0] # Threshold to binary mask\n",
    "        \n",
    "        # C. Post-process & Save\n",
    "        # Resizing the prediction (256x256) back to the original native resolution (e.g., 270x270).\n",
    "        orig_img = nib.load(item[\"image\"])\n",
    "        full_shape = orig_img.shape\n",
    "        spatial_shape = full_shape[:2] if len(full_shape) == 3 else full_shape\n",
    "        \n",
    "        # Resize to native resolution\n",
    "        resizer = Resize(spatial_size=spatial_shape, mode=\"nearest\")\n",
    "        mask_tensor_in = torch.from_numpy(start_mask).unsqueeze(0)\n",
    "        mask_tensor_out = resizer(mask_tensor_in) \n",
    "        final_mask = mask_tensor_out.squeeze(0).numpy()\n",
    "        \n",
    "        # Correct dimensions to match original NIfTI file (handle 2D vs 3D differences)\n",
    "        if len(full_shape) == 3 and full_shape[2] == 1:\n",
    "            final_mask = final_mask[:, :, np.newaxis]\n",
    "            \n",
    "        # Save pseudo-label as a NIfTI file\n",
    "        pseudo_filename = f\"pseudo_{os.path.basename(item['image'])}\"\n",
    "        pseudo_path = os.path.join(pseudo_label_dir, pseudo_filename)\n",
    "        nib.save(nib.Nifti1Image(final_mask.astype(np.float32), orig_img.affine), pseudo_path)\n",
    "        \n",
    "        pseudo_labeled_data.append({\"image\": item[\"image\"], \"label\": pseudo_path})\n",
    "\n",
    "print(f\"Generated {len(pseudo_labeled_data)} pseudo-labels in {pseudo_label_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae73f0",
   "metadata": {},
   "source": [
    "### 7.3. Train the Student\n",
    "The Student model is trained on the **Combined Dataset**:\n",
    "1.  **Labeled Data**: The original 50 Ground Truth examples.\n",
    "2.  **Pseudo-Labeled Data**: The 50 examples labeled by the Teacher.\n",
    "\n",
    "We generally use **Strong Augmentation** for the student to encourage it to learn robust features and smooth out the noise from the imperfect pseudo-labels. In this lab, we simply reuse the `augment=True` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Step 3: Training Student (N={len(pseudo_labeled_data) + n_labeled}) ---\")\n",
    "\n",
    "# 1. Combine Datasets\n",
    "labeled_data = train_pool[:n_labeled]\n",
    "combined_data = labeled_data + pseudo_labeled_data\n",
    "\n",
    "print(f\"Student Data: {len(labeled_data)} Gold Standard + {len(pseudo_labeled_data)} Pseudo-Labeled\")\n",
    "\n",
    "# 2. Define Loaders\n",
    "# Validation uses the SAME fixed validation set as always\n",
    "val_ds_student = CacheDataset(\n",
    "    data=val_files, \n",
    "    transform=get_transforms(augment=False), \n",
    "    cache_rate=1.0, num_workers=2\n",
    ")\n",
    "val_loader_student = DataLoader(val_ds_student, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "# Student Training Set\n",
    "student_ds = CacheDataset(\n",
    "    data=combined_data, \n",
    "    transform=get_transforms(augment=True), \n",
    "    cache_rate=1.0, num_workers=2\n",
    ")\n",
    "student_loader = DataLoader(student_ds, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# 3. Initialize Student Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "student_model = model_factory(cfg[\"model\"]).to(device)\n",
    "loss_fn = DiceCELoss(sigmoid=True, to_onehot_y=False)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-3)\n",
    "\n",
    "# 4. Train\n",
    "(student_losses, student_dices, student_best_dice, student_weights) = train_segmentation(\n",
    "    student_model, student_loader, val_loader_student,\n",
    "    loss_fn, dice_metric, optimizer,\n",
    "    device=device, max_epochs=ssl_epochs,\n",
    "    overlay_fn=None\n",
    ")\n",
    "\n",
    "print(f\"Student Best Validation Dice: {student_best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f3c395",
   "metadata": {},
   "source": [
    "### 7.4. Analysis\n",
    "We compare the Validation Dice curves of the Teacher (trained on only labeled data) and the Student (trained on labeled + pseudo-labeled data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03dddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Teacher\n",
    "plt.plot(teacher_dices, label=f'Teacher (N={n_labeled} Labeled)', color='m', linestyle='--')\n",
    "\n",
    "# Student\n",
    "plt.plot(student_dices, label=f'Student (N={n_labeled} GT + {n_unlabeled} Pseudo)', color='c', linewidth=2)\n",
    "\n",
    "# Oracle Baseline (if available from previous steps)\n",
    "if 'results_aug' in globals() and 100 in results_aug:\n",
    "     plt.plot(results_aug[100], label='Oracle (N=100 Labeled)', color='k', alpha=0.3)\n",
    "elif 'results_no_aug' in globals() and 100 in results_no_aug:\n",
    "     plt.plot(results_no_aug[100], label='Oracle (N=100 Labeled)', color='k', alpha=0.3)\n",
    "\n",
    "plt.title(\"Semi-Supervised Learning: Teacher vs Student\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Validation Dice\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfe395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai3.12",
   "language": "python",
   "name": "monai3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
