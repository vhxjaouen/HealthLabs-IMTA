{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6a65f7",
   "metadata": {},
   "source": [
    "<img src=\"./IMTA.png\" alt=\"Logo IMT Atlantique\" width=\"300\"/>\n",
    "\n",
    "##  **Introduction √† PyTorch/MONAI - Structuration d‚Äôun projet de Deep Learning**\n",
    "## TAF Health - UE B - 2025/2026 \n",
    "\n",
    "Pierre-Henri.Conze@imt-atlantique.fr - Vincent.Jaouen@imt-atlantique.fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750dbeb",
   "metadata": {},
   "source": [
    "**Objectifs** \n",
    "\n",
    "- Manipuler des images m√©dicales avec MONAI et PyTorch.\n",
    "-  Comprendre les grandes √©tapes d‚Äôun code d‚Äôapprentissage profond \n",
    "   - Pr√©paration des donn√©es (dataloader, transforms)\n",
    "   - D√©finition du mod√®le\n",
    "   - Boucle d‚Äôentra√Ænement\n",
    "   - Validation et inf√©rence\n",
    "- Mettre en place de bonnes pratiques de d√©veloppement en machine learning : \n",
    "   - Utilisation d'environnement virtuel\n",
    "   - Structuration du code avec des modules r√©utilisables (code factoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eaa69f",
   "metadata": {},
   "source": [
    "**Introduction √† MONAI**\n",
    "\n",
    "[MONAI](https://monai.io/) (Medical Open Network for AI) est une librairie open-source con√ßue pour le **deep learning en imagerie m√©dicale**.  \n",
    "D√©velopp√©e √† l‚Äôorigine par des √©quipes de NVIDIA et King‚Äôs College London, elle est devenue rapidement la **r√©f√©rence** pour la recherche et le d√©veloppement en IA appliqu√©e √† la sant√©.\n",
    "\n",
    "MONAI est b√¢tie **au-dessus de [PyTorch](https://pytorch.org/)** :  \n",
    "- elle h√©rite donc de la flexibilit√© et de la puissance de PyTorch (tensors, GPU, backpropagation, etc.),  \n",
    "- mais ajoute une surcouche sp√©cialis√©e pour les **besoins sp√©cifiques de l‚Äôimagerie m√©dicale**.\n",
    "\n",
    "---\n",
    "\n",
    "### Pourquoi MONAI en IA m√©dicale ?\n",
    "\n",
    "- **Sp√©cialis√©e pour l‚Äôimagerie 3D** : contrairement aux jeux de donn√©es classiques (ImageNet, photos 2D), l‚Äôimagerie m√©dicale est souvent volumique (IRM, scanner, TEP). MONAI g√®re nativement ces formats.  \n",
    "- **Transforms d√©di√©s** : des op√©rations adapt√©es (coupes 3D, interpolations m√©dicales, normalisations d‚Äôintensit√©, etc.) qui ne sont pas disponibles dans PyTorch \"pur\".  \n",
    "- **Formats standards** : compatibilit√© directe avec les formats de donn√©es cliniques (DICOM, NIfTI, etc.).  \n",
    "- **Exemples cliniques** : de nombreux mod√®les utilis√©s en imagerie m√©dicale sont disponibles, pour la segmentation de tumeurs, d√©tection de l√©sions, reconstruction, classification.  \n",
    "- **Communaut√© et adoption** : soutenue par NVIDIA, des h√¥pitaux, des universit√©s et des industriels, MONAI est devenu un standard de facto pour les publications et les projets acad√©miques.\n",
    "\n",
    "---\n",
    "\n",
    "### MONAI et PyTorch : un duo compl√©mentaire\n",
    "\n",
    "- **PyTorch** est le moteur : calcul diff√©rentiable, optimisation, gestion GPU/CPU.  \n",
    "- **MONAI** est la bo√Æte √† outils sp√©cialis√©e : chargement des images m√©dicales, pr√©traitements adapt√©s, r√©seaux neurones 3D pr√™ts √† l‚Äôemploi, m√©triques m√©dicales.  \n",
    "\n",
    "En r√©sum√© : **MONAI = PyTorch + expertise m√©dicale int√©gr√©e**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fc5d7",
   "metadata": {},
   "source": [
    "## Installation de l‚Äôenvironnement MONAI (CPU-only) local\n",
    "\n",
    "Pour ce TP, nous cr√©ons un environnement Python **local √† la machine TP** dans `/users/local/monai`.  \n",
    "Ce r√©pertoire est **en √©criture et rapide** (disque local), contrairement au `$HOME` sur NFS qui est lent.\n",
    "\n",
    "1. **Cr√©er l‚Äôenvironnement virtuel**\n",
    "   ```bash\n",
    "   $ python3 -m venv /users/local/monai\n",
    "\n",
    "2. **Activer l'environnement**\n",
    "    ```bash\n",
    "    $ source /users/local/monai/bin/activate\n",
    "Votre prompt devrait afficher `(monai)`.\n",
    "\n",
    "3. **Installer les d√©pendances : pytorch version cpu, monai, tools jupyter**\n",
    "    ```bash\n",
    "    $ pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio\n",
    "    $ pip install monai[all]\n",
    "    $ pip install ipykernel jupyterlab tqdm matplotlib \n",
    "\n",
    "4. **Enregistrer le kernel du venv dans Jupyter (utilisateur courant)**\n",
    "    ```bash\n",
    "    $ python -m ipykernel install --user --name=monai --display-name \"monai\"\n",
    "\n",
    "4. **Lancer JupyterLab et s√©lectionner le bon kernel**\n",
    "    ```bash\n",
    "    $ jupyter-lab\n",
    "Dans JupyterLab, choisissez le kernel Python (monai) pour vos notebooks.\n",
    "\n",
    "**R√©activation rapide (session suivante)**\n",
    "\n",
    "√Ä chaque nouvelle session (pas besoin de r√©installer) \n",
    "```bash\n",
    "   $ source /users/local/monai/bin/activate\n",
    "   $ jupyter-lab\n",
    "   ```\n",
    "**D√©sactivation (optionel)**\n",
    "\n",
    "Pour retourner au shell\n",
    "```bash\n",
    "    $ deactivate\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a9866",
   "metadata": {},
   "source": [
    "# Partie 1 ‚Äì Prise en main de MONAI\n",
    "Commen√ßons par charger une image IRM 3D avec MONAI et faisons des manipulations simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec39e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from monai.transforms import LoadImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO : change path to a NIfTI file\n",
    "img_path_t1ce = \"../datasets/3d_examples/BraTS-GLI-00000-000-t1c.nii.gz\"\n",
    "img_path_t2 = \"../datasets/3d_examples/BraTS-GLI-00000-000-t2w.nii.gz\"\n",
    "\n",
    "loader = LoadImage(image_only=True)\n",
    "img = loader(img_path_t1ce)\n",
    "\n",
    "print(\"Shape:\", img.shape)\n",
    "\n",
    "# Display one axial slice\n",
    "plt.imshow(img[:,:,img.shape[2]//2], cmap=\"gray\")\n",
    "plt.title(\"Coupe axiale\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96535e54",
   "metadata": {},
   "source": [
    "**Exercice 1.1** \n",
    "\n",
    "Cette image a √©t√© produite par IRM pond√©r√©e en T1 avec injection de produit contrastant au gadolinium. Le gadolinium est un agent paramagn√©tique particuli√®rement int√©ressant pour l'augmentation du contraste, m√™me si il pr√©sente des inconv√©nients (toxicit√©, polluant √©ternel). \n",
    "\n",
    "Elle montre un glioblastome c√©r√©bral dans la zone frontale du cerveau du patient (√† gauche sur cette coupe axiale).\n",
    "\n",
    "üëâ **Questions** : \n",
    "1. Afficher une coupe sagittale et coronale au niveau de cette tumeur\n",
    "2. Afficher l'image de pond√©ration T2. Pourquoi les contrastes sont invers√©s ?\n",
    "2. Changer la colormap de l'affichage\n",
    "3. Donner la valeur du voxel aux coordonn√©es (120,120,76)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce4cbc",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ae12f",
   "metadata": {},
   "source": [
    "### Exercice 1.2 ‚Äî Exploration des intensit√©s et premi√®res transforms\n",
    "\n",
    "Dans MONAI, on utilise des **`transforms`** pour appliquer des pr√©-traitements sur les images m√©dicales :  \n",
    "- `LoadImaged` : charge une image depuis le disque,  \n",
    "- `ScaleIntensityd` : ajuste l‚Äô√©chelle des intensit√©s,  \n",
    "- `NormalizeIntensityd` : centre et normalise les intensit√©s,  \n",
    "- `ToTensord` : convertit les donn√©es en tenseurs PyTorch.  \n",
    "\n",
    "üëâ La documentation compl√®te des transforms est disponible ici : [MONAI Transforms](https://docs.monai.io/en/stable/transforms.html).  \n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666baa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import LoadImaged, ScaleIntensityd, Compose\n",
    "\n",
    "# Exemple minimal : on d√©finit un pipeline de transforms\n",
    "transforms = Compose([\n",
    "    LoadImaged(keys=[\"t1ce\"]),         # Chargement\n",
    "    ScaleIntensityd(keys=[\"t1ce\"])     # Mise √† l‚Äô√©chelle des intensit√©s\n",
    "])\n",
    "\n",
    "# Application de la s√©quence de transforms\n",
    "data_dict = {\"t1ce\": img_path_t1ce}\n",
    "processed = transforms(data_dict)\n",
    "\n",
    "print(\"Type apr√®s transform :\", type(processed[\"t1ce\"]))\n",
    "print(\"Forme de l'image :\", processed[\"t1ce\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54563c86",
   "metadata": {},
   "source": [
    "üëâ **Questions** : \n",
    "\n",
    "1. Inspirez-vous de l‚Äôexemple ci-dessus pour appliquer un pipeline de transforms qui :\n",
    "   - charge l‚Äôimage,\n",
    "   - normalise les intensit√©s (`NormalizeIntensityd`),\n",
    "\n",
    "2. Affichez l‚Äôhistogramme des intensit√©s **avant et apr√®s normalisation**.  \n",
    "   *Aide : utilisez `plt.hist(processed[\"image\"].flatten(), bins=100)`.*\n",
    "\n",
    "3. Quelle est la nouvelle valeur du voxel aux coordonn√©es `(120, 120, 76)` apr√®s normalisation ?\n",
    "\n",
    "4. Comparez les intensit√©s moyennes entre :\n",
    "   - tissu c√©r√©bral sain,\n",
    "   - r√©gion tumorale.  \n",
    "   *(Indice : s√©lectionnez des r√©gions rectangulaires simples pour l‚Äôinstant.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fde3a",
   "metadata": {},
   "source": [
    "## Dataset et DataLoader\n",
    "\n",
    "En deep learning, on manipule g√©n√©ralement **un grand nombre de fichiers** (images, labels, masques, etc.).  \n",
    "Il est donc n√©cessaire d‚Äôavoir une organisation syst√©matique pour :\n",
    "- **acc√©der aux donn√©es** (charger depuis le disque),\n",
    "- **appliquer des pr√©-traitements** (normalisation, resize, etc.),\n",
    "- **les regrouper par lots (batchs)** pour les envoyer au r√©seau de neurones.\n",
    "\n",
    "PyTorch fournit deux briques essentielles :\n",
    "\n",
    "- **`Dataset`** : repr√©sente une *collection de donn√©es* (par exemple la liste des couples *image + label*).  \n",
    "- **`DataLoader`** : enveloppe le dataset et permet d‚Äôit√©rer dessus efficacement par *batchs* (gestion du parall√©lisme, m√©lange al√©atoire, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### Cas de l‚Äôimagerie m√©dicale\n",
    "\n",
    "En imagerie m√©dicale, les entr√©es sont souvent **coupl√©es** :  \n",
    "- une **image m√©dicale** (IRM, scanner, etc.),  \n",
    "- un **label ou masque associ√©** (segmentation, classification).  \n",
    "\n",
    "Par exemple, pour un probl√®me de segmentation tumorale, chaque **image IRM** est associ√©e √† un **masque de la tumeur**.  \n",
    "\n",
    "C‚Äôest ce que nous allons mettre en place ici avec MONAI.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5009537",
   "metadata": {},
   "source": [
    "## Dataset et DataLoader (version simple)\n",
    "\n",
    "Avant d‚Äôaller plus loin, cr√©ons un premier **Dataset** qui relie directement :\n",
    "- le chemin du fichier image (`img_fname`),\n",
    "- le chemin du fichier de segmentation (`seg_fname`).\n",
    "\n",
    "Cela correspond √† la mani√®re la plus simple d‚Äôorganiser nos donn√©es pour un probl√®me de **segmentation d‚Äôimages m√©dicales**.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemple de JSON de description des donn√©es\n",
    "\n",
    "Un fichier `dataset.json` contient une liste d‚Äôentr√©es au format :\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"training\": [\n",
    "    {\n",
    "      \"img\": \"/chemin/vers/img1.nii.gz\",\n",
    "      \"seg\": \"/chemin/vers/seg1.nii.gz\"\n",
    "    },\n",
    "    {\n",
    "      \"img\": \"/chemin/vers/img2.nii.gz\",\n",
    "      \"seg\": \"/chemin/vers/seg2.nii.gz\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695dc90e",
   "metadata": {},
   "source": [
    "Un exemple de dataset.json d√©j√† construit est disponible dans le dossier ../datasets/MidTumors/ reliant :\n",
    "- une image `trainA/BraTS_****_3c.nii.gz` \n",
    "- √† un masque de segmentation `trainB/BraTS_****_seg.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, Resized,\n",
    "    ScaleIntensityRangePercentilesd, EnsureTyped, Compose\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "import os, json\n",
    "\n",
    "# R√©pertoire des donn√©es (contenant dataset.json et les sous-dossiers trainA/trainB)\n",
    "data_dir = \"../datasets/MidTumors\"\n",
    "with open(os.path.join(data_dir, \"dataset.json\")) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# D√©finition des transforms de base\n",
    "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityRangePercentilesd, EnsureTyped, Lambdad\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),   # (H,W,3) ‚Üí (1,H,W,3)\n",
    "    ScaleIntensityRangePercentilesd(\n",
    "        keys=\"image\", lower=1, upper=99, b_min=-1.0, b_max=1.0, clip=True\n",
    "    ),\n",
    "    # Reorder dimensions: (C=1, H, W, 3) ‚Üí (3, H, W)\n",
    "    Lambdad(\n",
    "        keys=[\"image\",\"label\"],\n",
    "        func=lambda x: x.permute(3,1,2,0).squeeze(-1)   # (1,H,W,3) ‚Üí (3,H,W)\n",
    "    ),\n",
    "    EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "# On cr√©e les chemins complets depuis dataset.json\n",
    "train_files = [\n",
    "    {\n",
    "        \"image\": os.path.join(data_dir, f[\"image\"]),\n",
    "        \"label\": os.path.join(data_dir, f[\"label\"])\n",
    "    }\n",
    "    for f in data[\"training\"]   # juste 10 exemples pour l‚Äô√©nonc√©\n",
    "]\n",
    "\n",
    "# Cr√©ation Dataset + DataLoader\n",
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test d‚Äôune it√©ration\n",
    "batch = next(iter(train_loader))\n",
    "print(batch[\"image\"].shape, batch[\"label\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5de41",
   "metadata": {},
   "source": [
    "üëâ **Question** : Analysez l'image charg√©e par le mod√®le : \n",
    "\n",
    "- D√©terminez sa dimension. \n",
    "- Visualisez les 3 canaux \n",
    "\n",
    "En fait d'image tridimensionnelle, ``image`` est la m√™me coupe axiale d'un patient visualis√©e par trois s√©quences IRM diff√©rentes. Il est courant en IRM d'observer plusieurs types de contrastes. \n",
    "\n",
    "Un MONAI tensor doit : \n",
    "- en 3D, avoir des dimensions $N_{batchsize}\\times N_{channels} \\times N_x \\times N_y\\times N_z$\n",
    "- 2D doit, avoir des dimensions $N_{batchsize}\\times N_{channels} \\times N_x \\times N_y$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf93687",
   "metadata": {},
   "source": [
    "## Partie 3 ‚Äì Mod√®le et entra√Ænement\n",
    "\n",
    "Entra√Ænons d√©sormais un mod√®le de segmentation sur ces trois coupes. \n",
    "\n",
    "Nous devons d√©finir un DataLoader d'un Dataset que nous d√©finirons (cf TP pr√©c√©dent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e70b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Define model ---\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,     # RGB-like input\n",
    "    out_channels=1,    # binary segmentation\n",
    "    channels=(16, 32, 64),\n",
    "    strides=(2, 2),\n",
    ").to(device)\n",
    "\n",
    "# --- Loss & optimizer ---\n",
    "loss_fn = DiceCELoss(sigmoid=True, to_onehot_y=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --- Training loop ---\n",
    "max_epochs = 150\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:   # train_loader must yield dicts with \"image\" & \"label\"\n",
    "        inputs = batch[\"image\"].to(device)   # shape (B,3,H,W)\n",
    "        labels = batch[\"label\"].to(device)   # shape (B,1,H,W)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)              # (B,1,H,W)\n",
    "\n",
    "        # Loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{max_epochs}, Loss = {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe07eaa",
   "metadata": {},
   "source": [
    "Voil√†, vous avez un mod√®le de segmentation qui s'entraine sur 3 canaux !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422c019",
   "metadata": {},
   "source": [
    "## Partie 4 ‚Äì Structuration du code\n",
    "\n",
    "Jusqu‚Äô√† pr√©sent, nous avons identifi√© trois composants essentiels d‚Äôun projet de Deep Learning :  \n",
    "- Les **transforms**, qui assurent le pr√©traitement et la mise en forme des donn√©es.  \n",
    "- Le **DataLoader**, qui fournit des minibatches pendant l‚Äôentra√Ænement.  \n",
    "- La **boucle d‚Äôentra√Ænement** (*training loop*), qui met √† jour les poids du r√©seau par r√©tropropagation √† chaque it√©ration.  \n",
    "\n",
    "√Ä cela, il faut ajouter deux √©l√©ments indispensables dans toute exp√©rimentation s√©rieuse :  \n",
    "- **L‚Äô√©valuation**, permettant de calculer des m√©triques de validation et de visualiser les r√©sultats interm√©diaires.  \n",
    "- **La sauvegarde des poids**, afin de conserver le meilleur mod√®le selon un crit√®re de performance choisi.  \n",
    "\n",
    "---\n",
    "\n",
    "### Vers une structuration modulaire du code\n",
    "\n",
    "Pour rendre un code de Deep Learning fonctionnel et flexible, il est n√©cessaire d‚Äôadopter une organisation modulaire.  \n",
    "Une structuration typique consiste √† factoriser les diff√©rentes parties dans des fichiers distincts :  \n",
    "\n",
    "- `utils/data_utils.py` : d√©finition des loaders et des transformations.  \n",
    "- `utils/training.py` : impl√©mentation des boucles d‚Äôentra√Ænement.  \n",
    "- `utils/evaluation.py` : calcul des m√©triques et visualisation des r√©sultats.  \n",
    "- `inference/*.py` : scripts permettant d‚Äôappliquer un mod√®le entra√Æn√© √† de nouvelles donn√©es.  \n",
    "\n",
    "---\n",
    "\n",
    "### Mise en pratique dans les notebooks\n",
    "\n",
    "Dans ce cours, nous allons travailler √† partir de trois notebooks factoris√©s :  \n",
    "\n",
    "- `01_segmentation.ipynb`  \n",
    "- `02_classification.ipynb`  \n",
    "- `03_synthesis.ipynb`  \n",
    "\n",
    "Ces notebooks exploitent tous le dataset **MidTumors**, que nous avons bri√®vement explor√©.  \n",
    "L‚Äôint√©r√™t de cette factorisation est de permettre, dans un cadre commun, l‚Äôentra√Ænement de mod√®les r√©pondant √† des objectifs vari√©s :  \n",
    "\n",
    "- **Segmentation** : pr√©diction d‚Äôun masque √† partir des trois contrastes IRM.  \n",
    "- **Classification** : identification de la modalit√© (T1, T2, ou FLAIR).  \n",
    "- **Synth√®se** : g√©n√©ration d‚Äôune pseudo-modalit√© T2 √† partir d‚Äôune image T1.  \n",
    "\n",
    "Naturellement, les architectures de r√©seaux de neurones employ√©es diff√®rent selon la t√¢che, mais la structure de code sous-jacente reste la m√™me.  \n",
    "\n",
    "üëâ **Question** : Executez ces diff√©rents notebooks et analysez les. Identifiez les sp√©cificit√©s li√©es √† chaque t√¢che : configuration / mod√®les / data loader...\n",
    "\n",
    "---\n",
    "\n",
    "### Ouverture\n",
    "\n",
    "Une telle organisation ouvre la voie √† de nombreuses autres t√¢ches en adaptant les data loaders et les transforms. \n",
    "\n",
    "üëâ **Question** : adaptez ce travail √† un autre jeu de labels contenu dans `../datasets/MidTumors_3labels`, o√π les tumeurs sont cette fois d√©crites selon trois zones distinctes :  \n",
    "- **≈ìd√®me**,  \n",
    "- **c≈ìur tumoral (n√©crose/partie solide)**,  \n",
    "- **tumeur rehauss√©e** (*zones pr√©sentant une prise de contraste apr√®s injection de Gadolinium paramagn√©tique*).  \n",
    "\n",
    "üëâ **Bonus** : adaptez ce travail √† une nouvelle t√¢che (d√©bruitage? d√©floutage?)\n",
    "\n",
    "#### Exemples possibles\n",
    "- D√©bruitage\n",
    "- Defloutage \n",
    "- Apprentissage de mod√®les de normalisation inter-patients (r√©duction des biais li√©s aux contrastes).  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai312",
   "language": "python",
   "name": "monai312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
